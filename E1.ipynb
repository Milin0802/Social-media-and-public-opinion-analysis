{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感分析\n",
    "* 加载数据\n",
    "* 数据处理\n",
    "* 使用朴素贝叶斯进行情感分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = './data/aclImdb/train/'\n",
    "pos_path = path + 'pos/'\n",
    "neg_path = path + 'neg/'\n",
    "pos_files = [pos_path + x for x in \n",
    "\t\t\t filter(lambda x: x.endswith('.txt'), os.listdir(pos_path))]\n",
    "neg_files = [neg_path + x for x in \n",
    "\t\t\t filter(lambda x: x.endswith('.txt'), os.listdir(neg_path))]\n",
    "pos_list = [open(x, 'r', encoding='utf-8').read().lower() for x in pos_files]\n",
    "neg_list = [open(x, 'r', encoding='utf-8').read().lower() for x in neg_files]\n",
    "data_list = pos_list + neg_list\n",
    "labels_list = [1] * len(pos_list) + [0] * len(neg_list)\n",
    "# shuffle if you'd like ===========================\n",
    "from random import shuffle\n",
    "merged_data = list(zip(data_list, labels_list))\n",
    "shuffle(merged_data)\n",
    "data_list, label_list = list(zip(*merged_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"after a day at work, i sat down to relax and turned on the movie channels. the movie came up on the guide and sounded interesting so i tuned in just before it started. the first 30 minutes were enough to make me interested, but the lack of acting ability in jamie foxx and the slow plot movement made me want to get up and find food during the movie. if there is any credit to be given for acting in this movie it should go to david morse who at least tries to make the movie interesting. all in all, don't plan on impressing your friends by picking this one as a renter for a movie night.\",\n",
       " \"i saw the big bad swim at the 2006 temecula film festival, and was totally caught off guard by how much i was drawn into it.<br /><br />the film centers around the lives of a group of people taking an adult swim class for various reasons. a humorous idea in its own right, the class serves as a catalyst for greater changes in the students' lives.<br /><br />what surprised me about the film was how real it felt. rarely in ensemble pieces are characters treated so well. i enjoyed the scenes in the class immensely, and the drama that took place outside was very poignant. nothing seemed out of place or out of character, and ultimately it left a very strong feeling, much like attending school or summer camp - where you find fast friends, form strong bonds, and make discoveries about yourself, yet have to depart all too soon.<br /><br />my only complaint was that the character of paula had a very strong and unusual introduction, which made you want to know a little more about her than was ultimately revealed. i suppose you don't get to meet everyone in class, though...<br /><br />aside from this, i found the film very well-rounded and quite enjoyable. see it if you get the opportunity.\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(data_list),len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_vocab_size = 50000\n",
    "tokenizer = Tokenizer(num_words=max_vocab_size)\n",
    "tokenizer.fit_on_texts(data_list)\n",
    "# tokenizer.texts_to_matrix() input a list of raw text, return a numpy matrix\n",
    "# for one text to test\n",
    "tf_idf_data_121 = tokenizer.texts_to_matrix([data_list[121]], mode='tfidf') \n",
    "# for total text\n",
    "tf_idf_data = tokenizer.texts_to_matrix(data_list, mode='tfidf')\n",
    "# ===================================================\n",
    "# Implement this by yourself without this Tokenizer, it's also really easy. ^_^\n",
    "# Well you can just use it, enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, (50000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(tf_idf_data),tf_idf_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 2.14727243, 1.69492924, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "label_list = np.array(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 构建朴素贝叶斯模型\n",
    "* 与传统朴素贝叶斯不同 使用tf-idf 所以不分传统的混合模型，伯努利模型，多项式模型\n",
    "* 计算每一类概率P(Ci|w)分母相同，只计算分子\n",
    "* 使用条件独立假设建模分子中的 P(w|Ci) = P(w1|Ci)*... P(wn|Ci) 所以要建模 每一类的 prob log(P(wn|Ci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Model(object):\n",
    "    ## 朴素贝叶斯\n",
    "    def train(self,train_matrix,train_label):\n",
    "        \n",
    "        vector_len = len(train_matrix[0])\n",
    "        class_number = len(set(train_label))\n",
    "        item_number = len(train_matrix)\n",
    "        \n",
    "        self.vector_len = vector_len\n",
    "        self.class_number = class_number\n",
    "        self.item_number = item_number\n",
    "        \n",
    "        PC = {}\n",
    "        \n",
    "        # 先验概率\n",
    "        \n",
    "        for i in range(class_number):\n",
    "            PC[i] = 0.0\n",
    "        for label in train_label:\n",
    "            PC[label] += 1\n",
    "        \n",
    "        for i in range(class_number):\n",
    "            PC[i] = (PC[i]+1)/(item_number+class_number)\n",
    "        \n",
    "        print(PC)\n",
    "        \n",
    "        PWC = []\n",
    "        ## 每个类的词表概率\n",
    "        \n",
    "        vocb_ones_vector = np.ones(vector_len,)  #[vocab_size,]\n",
    "        \n",
    "        for n in range(class_number):\n",
    "            VCn = np.where(train_label == n) ## 加速            \n",
    "            VCn_vector = (np.sum(train_matrix[VCn],0) +1)/(len(VCn[0])+class_number) ## 加入平滑\n",
    "            PWC.append(np.log(VCn_vector))\n",
    "        \n",
    "        self.PWC = PWC\n",
    "        self.PC = PC\n",
    "        \n",
    "        print(\"Fit Successfully!\")\n",
    "        \n",
    "    def predict(self,vector):\n",
    "        ## 使用tf_idf 加权\n",
    "        PCW = []\n",
    "        ## 文档概率\n",
    "        for n in range(self.class_number):\n",
    "            PCW.append(self.PC[n]*np.sum(vector * self.PWC[n])) ## 使用向量对应乘而不是点乘加权\n",
    "        \n",
    "        return np.argmax(PCW) ## 分类结果\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.4995000416631947, 1: 0.5004999583368053}\n",
      "Fit Successfully!\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.train(tf_idf_data[:-1000],label_list[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 测试\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9450416666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label = []\n",
    "for v in tf_idf_data[:-1000]:\n",
    "    predict_label.append(model.predict(v))\n",
    "predict_label = np.array(predict_label)\n",
    "len(np.where(predict_label == label_list[:-1000])[0])/len(label_list[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label = []\n",
    "for v in tf_idf_data[-1000:]:\n",
    "    predict_label.append(model.predict(v))\n",
    "predict_label = np.array(predict_label)\n",
    "len(np.where(predict_label == label_list[-1000:])[0])/len(label_list[-1000:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
